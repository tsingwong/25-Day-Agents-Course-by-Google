{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21: ä¼˜ç§€ Agent è®¾è®¡æ¨¡å¼\n",
    "\n",
    "ä» Kaggle Capstone è·å¥–é¡¹ç›®ä¸­å­¦ä¹ çš„è®¾è®¡æ¨¡å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-Agent ç¼–æ’æ¨¡å¼\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†ç»™å¤šä¸ªä¸“èŒ Agentï¼Œæ¯ä¸ª Agent åªåšä¸€ä»¶äº‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. æ£€ç´¢: AI æœ€æ–°è¿›å±•\n",
      "   è·å–åˆ° 2 ç¯‡æ–‡ç« \n",
      "2. éªŒè¯æ¥æº...\n",
      "   2 ç¯‡é€šè¿‡éªŒè¯\n",
      "3. ç”Ÿæˆç®€æŠ¥...\n",
      "\n",
      "ğŸ“° ä»Šæ—¥ç®€æŠ¥:\n",
      "â€¢ AI çªç ´ (æ¥æº: TechNews)\n",
      "â€¢ æ–°æ¨¡å‹å‘å¸ƒ (æ¥æº: AIDaily)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "# å®šä¹‰ Agent åŸºç±»\n",
    "class BaseAgent(ABC):\n",
    "    \"\"\"æ‰€æœ‰ Agent çš„åŸºç±»\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process(self, input_data: Any) -> Any:\n",
    "        pass\n",
    "\n",
    "\n",
    "# ä¸“èŒ Agent ç¤ºä¾‹\n",
    "class RetrieverAgent(BaseAgent):\n",
    "    \"\"\"åªè´Ÿè´£è·å–æ•°æ®\"\"\"\n",
    "    \n",
    "    def process(self, query: str) -> list[dict]:\n",
    "        # æ¨¡æ‹Ÿè·å–æ–°é—»\n",
    "        return [\n",
    "            {\"title\": \"AI çªç ´\", \"source\": \"TechNews\", \"content\": \"...\"},\n",
    "            {\"title\": \"æ–°æ¨¡å‹å‘å¸ƒ\", \"source\": \"AIDaily\", \"content\": \"...\"},\n",
    "        ]\n",
    "\n",
    "\n",
    "class VerifierAgent(BaseAgent):\n",
    "    \"\"\"åªè´Ÿè´£éªŒè¯å†…å®¹çœŸå®æ€§\"\"\"\n",
    "    \n",
    "    def process(self, articles: list[dict]) -> list[dict]:\n",
    "        # æ¨¡æ‹ŸéªŒè¯ - æ£€æŸ¥æ˜¯å¦æœ‰å¯ä¿¡æ¥æº\n",
    "        verified = []\n",
    "        for article in articles:\n",
    "            if article.get(\"source\"):  # æœ‰æ¥æºæ‰é€šè¿‡\n",
    "                article[\"verified\"] = True\n",
    "                verified.append(article)\n",
    "        return verified\n",
    "\n",
    "\n",
    "class GeneratorAgent(BaseAgent):\n",
    "    \"\"\"åªè´Ÿè´£ç”Ÿæˆæ‘˜è¦\"\"\"\n",
    "    \n",
    "    def process(self, articles: list[dict]) -> str:\n",
    "        # æ¨¡æ‹Ÿç”Ÿæˆç®€æŠ¥\n",
    "        summaries = [f\"â€¢ {a['title']} (æ¥æº: {a['source']})\" for a in articles]\n",
    "        return \"\\n\".join(summaries)\n",
    "\n",
    "\n",
    "# ç¼–æ’å™¨ - åè°ƒå¤šä¸ª Agent\n",
    "class NewsOrchestrator:\n",
    "    \"\"\"Multi-Agent ç¼–æ’å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.retriever = RetrieverAgent()\n",
    "        self.verifier = VerifierAgent()\n",
    "        self.generator = GeneratorAgent()\n",
    "    \n",
    "    def run(self, query: str) -> str:\n",
    "        # æµæ°´çº¿æ‰§è¡Œ\n",
    "        print(f\"1. æ£€ç´¢: {query}\")\n",
    "        articles = self.retriever.process(query)\n",
    "        print(f\"   è·å–åˆ° {len(articles)} ç¯‡æ–‡ç« \")\n",
    "        \n",
    "        print(\"2. éªŒè¯æ¥æº...\")\n",
    "        verified = self.verifier.process(articles)\n",
    "        print(f\"   {len(verified)} ç¯‡é€šè¿‡éªŒè¯\")\n",
    "        \n",
    "        print(\"3. ç”Ÿæˆç®€æŠ¥...\")\n",
    "        result = self.generator.process(verified)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# è¿è¡Œ\n",
    "orchestrator = NewsOrchestrator()\n",
    "newsletter = orchestrator.run(\"AI æœ€æ–°è¿›å±•\")\n",
    "print(\"\\nğŸ“° ä»Šæ—¥ç®€æŠ¥:\")\n",
    "print(newsletter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Self-Correction Loop æ¨¡å¼\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: ç”¨ LLM è¯„ä¼°è¾“å‡ºè´¨é‡ï¼Œä¸è¾¾æ ‡å°±é‡æ–°ç”Ÿæˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ å°è¯• 1/3\n",
      "   ç”Ÿæˆ: AI æœ‰æ–°è¿›å±•... TODO\n",
      "   è¯„åˆ†: 33.3% - éœ€æ”¹è¿›: ['has_source', 'no_placeholder']\n",
      "   âŒ æœªé€šè¿‡ï¼Œç»§ç»­æ”¹è¿›...\n",
      "\n",
      "ğŸ”„ å°è¯• 2/3\n",
      "   ç”Ÿæˆ: AI æœ‰æ–°è¿›å±•ï¼Œè¯¦æƒ…å¾…è¡¥å……...\n",
      "   è¯„åˆ†: 33.3% - éœ€æ”¹è¿›: ['has_source', 'no_placeholder']\n",
      "   âŒ æœªé€šè¿‡ï¼Œç»§ç»­æ”¹è¿›...\n",
      "\n",
      "ğŸ”„ å°è¯• 3/3\n",
      "   ç”Ÿæˆ: AI æœ€æ–°è¿›å±•ï¼šGPT-5 å‘å¸ƒ (æ¥æº: OpenAI å®˜æ–¹åšå®¢)\n",
      "   è¯„åˆ†: 100.0% - è´¨é‡è¾¾æ ‡\n",
      "   âœ… é€šè¿‡!\n",
      "\n",
      "ğŸ“ æœ€ç»ˆç»“æœ: AI æœ€æ–°è¿›å±•ï¼šGPT-5 å‘å¸ƒ (æ¥æº: OpenAI å®˜æ–¹åšå®¢)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    passed: bool\n",
    "    score: float\n",
    "    feedback: str\n",
    "\n",
    "\n",
    "class QualityEvaluator:\n",
    "    \"\"\"è´¨é‡è¯„ä¼°å™¨ - æ¨¡æ‹Ÿ LLM è¯„ä¼°\"\"\"\n",
    "    \n",
    "    def __init__(self, threshold: float = 0.7):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def evaluate(self, content: str) -> EvaluationResult:\n",
    "        # æ¨¡æ‹Ÿè¯„ä¼°é€»è¾‘\n",
    "        checks = {\n",
    "            \"has_content\": len(content) > 10,\n",
    "            \"has_source\": \"æ¥æº\" in content or \"source\" in content.lower(),\n",
    "            \"no_placeholder\": \"...\" not in content and \"TODO\" not in content,\n",
    "        }\n",
    "        \n",
    "        score = sum(checks.values()) / len(checks)\n",
    "        \n",
    "        if score >= self.threshold:\n",
    "            return EvaluationResult(True, score, \"è´¨é‡è¾¾æ ‡\")\n",
    "        else:\n",
    "            failed = [k for k, v in checks.items() if not v]\n",
    "            return EvaluationResult(False, score, f\"éœ€æ”¹è¿›: {failed}\")\n",
    "\n",
    "\n",
    "class SelfCorrectingAgent:\n",
    "    \"\"\"è‡ªçº é”™ Agent\"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3):\n",
    "        self.max_retries = max_retries\n",
    "        self.evaluator = QualityEvaluator()\n",
    "        self.attempt = 0\n",
    "    \n",
    "    def generate(self, task: str, feedback: str = \"\") -> str:\n",
    "        \"\"\"æ¨¡æ‹Ÿç”Ÿæˆ - æ ¹æ®åé¦ˆæ”¹è¿›\"\"\"\n",
    "        self.attempt += 1\n",
    "        \n",
    "        if self.attempt == 1:\n",
    "            # ç¬¬ä¸€æ¬¡ï¼šä½è´¨é‡è¾“å‡º\n",
    "            return \"AI æœ‰æ–°è¿›å±•... TODO\"\n",
    "        elif self.attempt == 2:\n",
    "            # ç¬¬äºŒæ¬¡ï¼šæ”¹è¿›ä½†ä»æœ‰é—®é¢˜\n",
    "            return \"AI æœ‰æ–°è¿›å±•ï¼Œè¯¦æƒ…å¾…è¡¥å……...\"\n",
    "        else:\n",
    "            # ç¬¬ä¸‰æ¬¡ï¼šé«˜è´¨é‡è¾“å‡º\n",
    "            return \"AI æœ€æ–°è¿›å±•ï¼šGPT-5 å‘å¸ƒ (æ¥æº: OpenAI å®˜æ–¹åšå®¢)\"\n",
    "    \n",
    "    def run(self, task: str) -> str:\n",
    "        feedback = \"\"\n",
    "        \n",
    "        for attempt in range(1, self.max_retries + 1):\n",
    "            print(f\"\\nğŸ”„ å°è¯• {attempt}/{self.max_retries}\")\n",
    "            \n",
    "            result = self.generate(task, feedback)\n",
    "            print(f\"   ç”Ÿæˆ: {result}\")\n",
    "            \n",
    "            evaluation = self.evaluator.evaluate(result)\n",
    "            print(f\"   è¯„åˆ†: {evaluation.score:.1%} - {evaluation.feedback}\")\n",
    "            \n",
    "            if evaluation.passed:\n",
    "                print(\"   âœ… é€šè¿‡!\")\n",
    "                return result\n",
    "            \n",
    "            feedback = evaluation.feedback\n",
    "            print(f\"   âŒ æœªé€šè¿‡ï¼Œç»§ç»­æ”¹è¿›...\")\n",
    "        \n",
    "        raise Exception(\"æ— æ³•è¾¾åˆ°è´¨é‡æ ‡å‡†\")\n",
    "\n",
    "\n",
    "# è¿è¡Œè‡ªçº é”™æµç¨‹\n",
    "agent = SelfCorrectingAgent()\n",
    "final_result = agent.run(\"å†™ä¸€æ¡ AI æ–°é—»\")\n",
    "print(f\"\\nğŸ“ æœ€ç»ˆç»“æœ: {final_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Citation Verification æ¨¡å¼\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: æ¯ä¸ªå£°æ˜éƒ½å¿…é¡»æœ‰å¯è¿½æº¯çš„æ¥æºï¼Œå®ç°é›¶å¹»è§‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ— æ³•éªŒè¯: æŸå…¬å¸è‚¡ä»·ä¸Šæ¶¨ 100%\n",
      "\n",
      "âœ… å·²éªŒè¯çš„å£°æ˜:\n",
      "  â€¢ GPT-5 å°†äº 2025 å¹´å‘å¸ƒ\n",
      "    ğŸ“ æ¥æº: OpenAI Blog (https://openai.com/blog)\n",
      "    ğŸ¯ ç½®ä¿¡åº¦: 95%\n",
      "  â€¢ Gemini 2.0 æ”¯æŒå¤šæ¨¡æ€\n",
      "    ğŸ“ æ¥æº: Google AI Blog (https://ai.google/blog)\n",
      "    ğŸ¯ ç½®ä¿¡åº¦: 95%\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Citation:\n",
    "    \"\"\"å¼•ç”¨æ¥æº\"\"\"\n",
    "    source: str\n",
    "    url: str\n",
    "    accessed_at: str\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class VerifiedClaim:\n",
    "    \"\"\"å¸¦å¼•ç”¨çš„å£°æ˜\"\"\"\n",
    "    claim: str\n",
    "    citation: Citation\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "class CitationVerifier:\n",
    "    \"\"\"å¼•ç”¨éªŒè¯å™¨\"\"\"\n",
    "    \n",
    "    def verify_and_cite(self, claims: list[str], sources: list[dict]) -> list[VerifiedClaim]:\n",
    "        \"\"\"ä¸ºæ¯ä¸ªå£°æ˜æ‰¾åˆ°å¹¶éªŒè¯å¼•ç”¨\"\"\"\n",
    "        verified_claims = []\n",
    "        \n",
    "        for claim in claims:\n",
    "            # æ¨¡æ‹ŸæŸ¥æ‰¾åŒ¹é…çš„æ¥æº\n",
    "            matching_source = self._find_source(claim, sources)\n",
    "            \n",
    "            if matching_source:\n",
    "                verified_claims.append(VerifiedClaim(\n",
    "                    claim=claim,\n",
    "                    citation=Citation(\n",
    "                        source=matching_source[\"name\"],\n",
    "                        url=matching_source[\"url\"],\n",
    "                        accessed_at=\"2025-12-29\"\n",
    "                    ),\n",
    "                    confidence=0.95\n",
    "                ))\n",
    "            else:\n",
    "                print(f\"âš ï¸ æ— æ³•éªŒè¯: {claim}\")\n",
    "        \n",
    "        return verified_claims\n",
    "    \n",
    "    def _find_source(self, claim: str, sources: list[dict]) -> dict | None:\n",
    "        \"\"\"æ¨¡æ‹Ÿè¯­ä¹‰åŒ¹é…æŸ¥æ‰¾æ¥æº\"\"\"\n",
    "        for source in sources:\n",
    "            # ç®€åŒ–ï¼šå…³é”®è¯åŒ¹é…\n",
    "            if any(kw in claim.lower() for kw in source.get(\"keywords\", [])):\n",
    "                return source\n",
    "        return None\n",
    "\n",
    "\n",
    "# ç¤ºä¾‹ï¼šéªŒè¯å£°æ˜\n",
    "claims = [\n",
    "    \"GPT-5 å°†äº 2025 å¹´å‘å¸ƒ\",\n",
    "    \"Gemini 2.0 æ”¯æŒå¤šæ¨¡æ€\",\n",
    "    \"æŸå…¬å¸è‚¡ä»·ä¸Šæ¶¨ 100%\",  # æ— æ¥æº\n",
    "]\n",
    "\n",
    "sources = [\n",
    "    {\"name\": \"OpenAI Blog\", \"url\": \"https://openai.com/blog\", \"keywords\": [\"gpt\", \"openai\"]},\n",
    "    {\"name\": \"Google AI Blog\", \"url\": \"https://ai.google/blog\", \"keywords\": [\"gemini\", \"google\"]},\n",
    "]\n",
    "\n",
    "verifier = CitationVerifier()\n",
    "verified = verifier.verify_and_cite(claims, sources)\n",
    "\n",
    "print(\"\\nâœ… å·²éªŒè¯çš„å£°æ˜:\")\n",
    "for vc in verified:\n",
    "    print(f\"  â€¢ {vc.claim}\")\n",
    "    print(f\"    ğŸ“ æ¥æº: {vc.citation.source} ({vc.citation.url})\")\n",
    "    print(f\"    ğŸ¯ ç½®ä¿¡åº¦: {vc.confidence:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Feedback Loop æ¨¡å¼\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: ä»ç”¨æˆ·åé¦ˆä¸­å­¦ä¹ ï¼ŒæŒç»­æ”¹è¿› Agent è¡Œä¸ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ”¶é›†ç”¨æˆ·åé¦ˆ...\n",
      "  news_1: â­3 - ['too_long', 'relevant']\n",
      "  news_2: â­4 - ['technical', 'accurate']\n",
      "  news_3: â­2 - ['too_long', 'irrelevant']\n",
      "  news_4: â­5 - ['technical', 'relevant', 'accurate']\n",
      "  news_5: â­4 - ['technical']\n",
      "\n",
      "ğŸ“ˆ å­¦ä¹ åˆ°çš„åå¥½:\n",
      "  avg_rating: 3.6\n",
      "  wants_shorter: True\n",
      "  wants_more_detail: False\n",
      "  prefers_technical: True\n",
      "\n",
      "ğŸ¯ ç”Ÿæˆæç¤º (ç”¨äºè°ƒæ•´ Agent):\n",
      "  max_length: short\n",
      "  style: technical\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UserFeedback:\n",
    "    \"\"\"ç”¨æˆ·åé¦ˆ\"\"\"\n",
    "    content_id: str\n",
    "    rating: int  # 1-5\n",
    "    tags: list[str]  # [\"relevant\", \"accurate\", \"too_long\", etc.]\n",
    "\n",
    "\n",
    "class FeedbackLearner:\n",
    "    \"\"\"åé¦ˆå­¦ä¹ å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feedback_history: list[UserFeedback] = []\n",
    "        self.tag_stats = defaultdict(int)\n",
    "        self.preferences = {}\n",
    "    \n",
    "    def record_feedback(self, feedback: UserFeedback):\n",
    "        \"\"\"è®°å½•åé¦ˆ\"\"\"\n",
    "        self.feedback_history.append(feedback)\n",
    "        for tag in feedback.tags:\n",
    "            self.tag_stats[tag] += 1\n",
    "        self._update_preferences()\n",
    "    \n",
    "    def _update_preferences(self):\n",
    "        \"\"\"æ ¹æ®åé¦ˆæ›´æ–°åå¥½\"\"\"\n",
    "        total = len(self.feedback_history)\n",
    "        if total == 0:\n",
    "            return\n",
    "        \n",
    "        # è®¡ç®—å„æ ‡ç­¾æ¯”ä¾‹\n",
    "        self.preferences = {\n",
    "            \"avg_rating\": sum(f.rating for f in self.feedback_history) / total,\n",
    "            \"wants_shorter\": self.tag_stats[\"too_long\"] / total > 0.3,\n",
    "            \"wants_more_detail\": self.tag_stats[\"too_brief\"] / total > 0.3,\n",
    "            \"prefers_technical\": self.tag_stats[\"technical\"] / total > 0.5,\n",
    "        }\n",
    "    \n",
    "    def get_generation_hints(self) -> dict:\n",
    "        \"\"\"è·å–ç”Ÿæˆæç¤ºï¼Œç”¨äºè°ƒæ•´ Agent è¡Œä¸º\"\"\"\n",
    "        hints = {}\n",
    "        \n",
    "        if self.preferences.get(\"wants_shorter\"):\n",
    "            hints[\"max_length\"] = \"short\"\n",
    "        elif self.preferences.get(\"wants_more_detail\"):\n",
    "            hints[\"max_length\"] = \"detailed\"\n",
    "        \n",
    "        if self.preferences.get(\"prefers_technical\"):\n",
    "            hints[\"style\"] = \"technical\"\n",
    "        else:\n",
    "            hints[\"style\"] = \"casual\"\n",
    "        \n",
    "        return hints\n",
    "\n",
    "\n",
    "# æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆå¾ªç¯\n",
    "learner = FeedbackLearner()\n",
    "\n",
    "# æ¨¡æ‹Ÿæ”¶é›†åé¦ˆ\n",
    "feedbacks = [\n",
    "    UserFeedback(\"news_1\", 3, [\"too_long\", \"relevant\"]),\n",
    "    UserFeedback(\"news_2\", 4, [\"technical\", \"accurate\"]),\n",
    "    UserFeedback(\"news_3\", 2, [\"too_long\", \"irrelevant\"]),\n",
    "    UserFeedback(\"news_4\", 5, [\"technical\", \"relevant\", \"accurate\"]),\n",
    "    UserFeedback(\"news_5\", 4, [\"technical\"]),\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š æ”¶é›†ç”¨æˆ·åé¦ˆ...\")\n",
    "for fb in feedbacks:\n",
    "    learner.record_feedback(fb)\n",
    "    print(f\"  {fb.content_id}: â­{fb.rating} - {fb.tags}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ å­¦ä¹ åˆ°çš„åå¥½:\")\n",
    "for k, v in learner.preferences.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ç”Ÿæˆæç¤º (ç”¨äºè°ƒæ•´ Agent):\")\n",
    "hints = learner.get_generation_hints()\n",
    "for k, v in hints.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å®Œæ•´ç¤ºä¾‹ï¼šNewsPulse é£æ ¼çš„ Agent\n",
    "\n",
    "æ•´åˆä»¥ä¸Šæ‰€æœ‰æ¨¡å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åé¦ˆå·²è®°å½•: old_1\n",
      "âœ… åé¦ˆå·²è®°å½•: old_2\n",
      "==================================================\n",
      "ğŸš€ ç”Ÿæˆç®€æŠ¥: AI æœ€æ–°åŠ¨æ€\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ ç”¨æˆ·åå¥½: {'max_length': 'short', 'style': 'casual'}\n",
      "\n",
      "ğŸ” Step 1: æ£€ç´¢æ–°é—»...\n",
      "\n",
      "âœ… Step 2: éªŒè¯æ¥æº...\n",
      "\n",
      "ğŸ“ Step 3: ç”Ÿæˆç®€æŠ¥ (with self-correction)...\n",
      "   å°è¯• 1: è¯„åˆ† 100%\n",
      "\n",
      "ğŸ‰ ç”Ÿæˆå®Œæˆ!\n",
      "\n",
      "==================================================\n",
      "ğŸ“° æœ€ç»ˆè¾“å‡º:\n",
      "==================================================\n",
      "å†…å®¹: â€¢ AI çªç ´ (æ¥æº: TechNews)\n",
      "â€¢ æ–°æ¨¡å‹å‘å¸ƒ (æ¥æº: AIDaily)\n",
      "æ¥æº: ['TechNews', 'AIDaily']\n",
      "è´¨é‡: 100%\n"
     ]
    }
   ],
   "source": [
    "class NewsPulseStyleAgent:\n",
    "    \"\"\"æ•´åˆæ‰€æœ‰è®¾è®¡æ¨¡å¼çš„ Agent\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Multi-Agent\n",
    "        self.retriever = RetrieverAgent()\n",
    "        self.verifier = VerifierAgent()\n",
    "        self.generator = GeneratorAgent()\n",
    "        \n",
    "        # Quality Control\n",
    "        self.evaluator = QualityEvaluator(threshold=0.6)\n",
    "        \n",
    "        # Citation\n",
    "        self.citation_verifier = CitationVerifier()\n",
    "        \n",
    "        # Feedback Learning\n",
    "        self.feedback_learner = FeedbackLearner()\n",
    "    \n",
    "    def generate_newsletter(self, query: str, max_retries: int = 3) -> dict:\n",
    "        \"\"\"ç”Ÿæˆæ–°é—»ç®€æŠ¥ - å®Œæ•´æµç¨‹\"\"\"\n",
    "        \n",
    "        print(\"=\"*50)\n",
    "        print(f\"ğŸš€ ç”Ÿæˆç®€æŠ¥: {query}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 1. è·å–ç”¨æˆ·åå¥½\n",
    "        hints = self.feedback_learner.get_generation_hints()\n",
    "        print(f\"\\nğŸ“‹ ç”¨æˆ·åå¥½: {hints}\")\n",
    "        \n",
    "        # 2. Multi-Agent æµæ°´çº¿\n",
    "        print(\"\\nğŸ” Step 1: æ£€ç´¢æ–°é—»...\")\n",
    "        articles = self.retriever.process(query)\n",
    "        \n",
    "        print(\"\\nâœ… Step 2: éªŒè¯æ¥æº...\")\n",
    "        verified_articles = self.verifier.process(articles)\n",
    "        \n",
    "        # 3. Self-Correction Loop\n",
    "        print(\"\\nğŸ“ Step 3: ç”Ÿæˆç®€æŠ¥ (with self-correction)...\")\n",
    "        for attempt in range(1, max_retries + 1):\n",
    "            content = self.generator.process(verified_articles)\n",
    "            \n",
    "            # è¯„ä¼°è´¨é‡\n",
    "            eval_result = self.evaluator.evaluate(content)\n",
    "            print(f\"   å°è¯• {attempt}: è¯„åˆ† {eval_result.score:.0%}\")\n",
    "            \n",
    "            if eval_result.passed:\n",
    "                break\n",
    "        \n",
    "        print(\"\\nğŸ‰ ç”Ÿæˆå®Œæˆ!\")\n",
    "        \n",
    "        return {\n",
    "            \"content\": content,\n",
    "            \"sources\": [a[\"source\"] for a in verified_articles],\n",
    "            \"quality_score\": eval_result.score,\n",
    "        }\n",
    "    \n",
    "    def collect_feedback(self, content_id: str, rating: int, tags: list[str]):\n",
    "        \"\"\"æ”¶é›†ç”¨æˆ·åé¦ˆ\"\"\"\n",
    "        feedback = UserFeedback(content_id, rating, tags)\n",
    "        self.feedback_learner.record_feedback(feedback)\n",
    "        print(f\"âœ… åé¦ˆå·²è®°å½•: {content_id}\")\n",
    "\n",
    "\n",
    "# è¿è¡Œå®Œæ•´ç¤ºä¾‹\n",
    "agent = NewsPulseStyleAgent()\n",
    "\n",
    "# æ¨¡æ‹Ÿä¸€äº›å†å²åé¦ˆ\n",
    "agent.collect_feedback(\"old_1\", 4, [\"technical\"])\n",
    "agent.collect_feedback(\"old_2\", 3, [\"too_long\"])\n",
    "\n",
    "# ç”Ÿæˆæ–°ç®€æŠ¥\n",
    "result = agent.generate_newsletter(\"AI æœ€æ–°åŠ¨æ€\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“° æœ€ç»ˆè¾“å‡º:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"å†…å®¹: {result['content']}\")\n",
    "print(f\"æ¥æº: {result['sources']}\")\n",
    "print(f\"è´¨é‡: {result['quality_score']:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¾è®¡æ£€æŸ¥æ¸…å•\n",
    "\n",
    "åœ¨æ„å»º Agent æ—¶ï¼Œæ£€æŸ¥ä»¥ä¸‹è¦ç‚¹ï¼š\n",
    "\n",
    "- [ ] **é—®é¢˜å®šä¹‰** - æ˜¯å¦è¶³å¤Ÿå…·ä½“ï¼Ÿ\n",
    "- [ ] **Multi-Agent** - æ˜¯å¦éœ€è¦æ‹†åˆ†æˆå¤šä¸ªä¸“èŒ Agentï¼Ÿ\n",
    "- [ ] **Self-Correction** - æœ‰æ²¡æœ‰è´¨é‡è¯„ä¼°å’Œè‡ªçº é”™æœºåˆ¶ï¼Ÿ\n",
    "- [ ] **Citation** - è¾“å‡ºæ˜¯å¦å¯è¿½æº¯ï¼ˆæœ‰å¼•ç”¨æ¥æºï¼‰ï¼Ÿ\n",
    "- [ ] **Feedback Loop** - æ˜¯å¦æœ‰ç”¨æˆ·åé¦ˆçš„å­¦ä¹ æœºåˆ¶ï¼Ÿ\n",
    "- [ ] **MCP æ ‡å‡†åŒ–** - å·¥å…·èƒ½åŠ›æ˜¯å¦é€šè¿‡ MCP æ ‡å‡†åŒ–ï¼Ÿ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
