{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 17: Gemini 3 Flash - å¯é…ç½®æ€è€ƒçº§åˆ«\n",
    "\n",
    "Gemini 3 Flash æœ€å¤§äº®ç‚¹ï¼š**Thinking Levelï¼ˆæ€è€ƒçº§åˆ«ï¼‰**\n",
    "\n",
    "ç®€å•è¯´ï¼šæ§åˆ¶æ¨¡å‹\"æƒ³å¤šä¹…\"å†å›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. æ€è€ƒçº§åˆ«ä¸€è§ˆ\n",
    "\n",
    "| çº§åˆ« | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|------|----------|\n",
    "| `MINIMAL` | æœ€å¿«å“åº” | ç®€å•é—®ç­”ã€èŠå¤© |\n",
    "| `LOW` | å¿«é€Ÿ + å°‘é‡æ¨ç† | æ—¥å¸¸ä»»åŠ¡ |\n",
    "| `MEDIUM` | å¹³è¡¡æ¨¡å¼ | ä¸­ç­‰å¤æ‚åº¦ |\n",
    "| `HIGH` | æ·±åº¦æ¨ç† | æ•°å­¦ã€ç¼–ç¨‹ã€å¤æ‚é—®é¢˜ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ç¡®è®¤ API Key å·²è®¾ç½®\n",
    "assert os.getenv(\"GOOGLE_API_KEY\"), \"è¯·è®¾ç½® GOOGLE_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.planners import BuiltInPlanner\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "from google.genai.types import Content, Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ ¸å¿ƒé…ç½®ï¼šThinkingConfig\n",
    "\n",
    "å…³é”®ä»£ç å°±è¿™å‡ è¡Œï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ€è€ƒçº§åˆ«: ThinkingLevel.LOW\n"
     ]
    }
   ],
   "source": [
    "# é…ç½®æ€è€ƒçº§åˆ«\n",
    "thinking_config = types.ThinkingConfig(\n",
    "    thinking_level=\"LOW\"  # å¯é€‰: MINIMAL, LOW, MEDIUM, HIGH\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè§„åˆ’å™¨\n",
    "planner = BuiltInPlanner(thinking_config=thinking_config)\n",
    "\n",
    "print(f\"æ€è€ƒçº§åˆ«: {thinking_config.thinking_level}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å®šä¹‰å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time(city: str) -> dict:\n",
    "    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å½“å‰æ—¶é—´\"\"\"\n",
    "    times = {\n",
    "        \"åŒ—äº¬\": \"22:30\",\n",
    "        \"ä¸œäº¬\": \"23:30\", \n",
    "        \"çº½çº¦\": \"09:30\",\n",
    "        \"ä¼¦æ•¦\": \"14:30\",\n",
    "    }\n",
    "    time = times.get(city, \"10:00\")\n",
    "    return {\"city\": city, \"time\": time}\n",
    "\n",
    "\n",
    "def calculate(expression: str) -> dict:\n",
    "    \"\"\"è®¡ç®—æ•°å­¦è¡¨è¾¾å¼\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return {\"expression\": expression, \"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. åˆ›å»º Agent å·¥å‚å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·¥å‚å‡½æ•°å·²å®šä¹‰\n"
     ]
    }
   ],
   "source": [
    "def create_agent(thinking_level: str) -> Agent:\n",
    "    \"\"\"åˆ›å»ºæŒ‡å®šæ€è€ƒçº§åˆ«çš„ Agent\"\"\"\n",
    "    return Agent(\n",
    "        model='gemini-3-flash-preview',\n",
    "        name=f'agent_{thinking_level.lower()}',\n",
    "        instruction=\"ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡ç®€æ´å›ç­”ã€‚\",\n",
    "        tools=[get_current_time, calculate],\n",
    "        planner=BuiltInPlanner(\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_level=thinking_level\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "print(\"âœ… å·¥å‚å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è¿è¡Œè¾…åŠ©å‡½æ•°ï¼ˆå«æ€è€ƒè¿‡ç¨‹æ˜¾ç¤ºï¼‰\n",
    "\n",
    "å…³é”®ï¼šé€šè¿‡ `event.content.parts` ä¸­çš„ `thought` å±æ€§è·å–æ€è€ƒå†…å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è¾…åŠ©å‡½æ•°å·²å®šä¹‰ï¼ˆæ”¯æŒæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼‰\n"
     ]
    }
   ],
   "source": [
    "session_service = InMemorySessionService()\n",
    "\n",
    "async def ask(agent: Agent, question: str, show_thinking: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    å‘ Agent æé—®å¹¶è¿”å›å›ç­”\n",
    "    \n",
    "    å‚æ•°:\n",
    "        show_thinking: æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹\n",
    "    \"\"\"\n",
    "    session = await session_service.create_session(\n",
    "        app_name=\"day17_demo\",\n",
    "        user_id=\"demo_user\"\n",
    "    )\n",
    "    \n",
    "    runner = Runner(\n",
    "        agent=agent,\n",
    "        app_name=\"day17_demo\", \n",
    "        session_service=session_service\n",
    "    )\n",
    "    \n",
    "    user_content = Content(role=\"user\", parts=[Part(text=question)])\n",
    "    \n",
    "    response = \"\"\n",
    "    thinking = \"\"\n",
    "    \n",
    "    async for event in runner.run_async(\n",
    "        user_id=\"demo_user\",\n",
    "        session_id=session.id,\n",
    "        new_message=user_content\n",
    "    ):\n",
    "        if hasattr(event, 'content') and event.content:\n",
    "            if hasattr(event.content, 'parts'):\n",
    "                for part in event.content.parts:\n",
    "                    # è·å–æ€è€ƒè¿‡ç¨‹\n",
    "                    if hasattr(part, 'thought') and part.thought:\n",
    "                        thinking += part.text if hasattr(part, 'text') else \"\"\n",
    "                    # è·å–æœ€ç»ˆå›ç­”\n",
    "                    elif hasattr(part, 'text') and part.text:\n",
    "                        response += part.text\n",
    "    \n",
    "    # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹\n",
    "    if show_thinking and thinking:\n",
    "        print(f\"ğŸ’­ æ€è€ƒè¿‡ç¨‹:\\n{thinking}\\n\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"âœ… è¾…åŠ©å‡½æ•°å·²å®šä¹‰ï¼ˆæ”¯æŒæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æµ‹è¯•ï¼šLOW çº§åˆ«ï¼ˆæ—¥å¸¸ä½¿ç”¨æ¨èï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– [LOW] å›ç­”: ç°åœ¨åŒ—äº¬æ—¶é—´æ˜¯ 22:30ã€‚\n"
     ]
    }
   ],
   "source": [
    "agent_low = create_agent(\"LOW\")\n",
    "\n",
    "response = await ask(agent_low, \"åŒ—äº¬ç°åœ¨å‡ ç‚¹ï¼Ÿ\")\n",
    "print(f\"ğŸ¤– [LOW] å›ç­”: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æµ‹è¯•ï¼šHIGH çº§åˆ«ï¼ˆå¤æ‚æ¨ç†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– [HIGH] å›ç­”: åŒ—äº¬æ™šä¸Š10ç‚¹ï¼ˆ22:00ï¼‰ï¼Œçº½çº¦æ˜¯å½“æ—¥**ä¸Šåˆ10ç‚¹**ï¼ˆç›®å‰å¤„äºå¤ä»¤æ—¶ï¼‰ã€‚å¦‚æœæ˜¯å†¬ä»¤æ—¶ï¼Œåˆ™ä¸ºä¸Šåˆ9ç‚¹ã€‚\n",
      "\n",
      "**æ—¶å·®åŸå› ï¼š**\n",
      "1. **åœ°çƒè‡ªè½¬**ï¼šåœ°çƒè‡ªè¥¿å‘ä¸œè‡ªè½¬ï¼Œä¸åŒç»åº¦çš„åœ°åŒºçœ‹åˆ°æ—¥å‡ºçš„æ—¶é—´ä¸åŒã€‚\n",
      "2. **æ—¶åŒºåˆ’åˆ†**ï¼šä¸ºç»Ÿä¸€æ—¶é—´ï¼Œå…¨çƒåˆ†ä¸º24ä¸ªæ—¶åŒºã€‚åŒ—äº¬ä½äº**ä¸œå…«åŒº (UTC+8)**ï¼Œçº½çº¦ä½äº**è¥¿äº”åŒº (UTC-5)**ã€‚\n",
      "3. **å¤ä»¤æ—¶**ï¼šçº½çº¦åœ¨å¤å­£ä¼šè¿›å…¥å¤ä»¤æ—¶ï¼Œå°†æ—¶é’Ÿæ‹¨å¿«ä¸€å°æ—¶ï¼ˆå˜ä¸ºUTC-4ï¼‰ï¼Œå› æ­¤ä¸¤åœ°ç›®å‰çš„æ—¶å·®ä¸º12å°æ—¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "agent_high = create_agent(\"HIGH\")\n",
    "\n",
    "response = await ask(agent_high, \"å¦‚æœåŒ—äº¬æ˜¯æ™šä¸Š10ç‚¹ï¼Œçº½çº¦æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿè§£é‡Šæ—¶å·®åŸå› ã€‚\")\n",
    "print(f\"ğŸ¤– [HIGH] å›ç­”: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æµ‹è¯•ï¼šæ•°å­¦è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– [LOW] å›ç­”: ç»“æœæ˜¯ 126ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = await ask(agent_low, \"è®¡ç®— (15 * 8) + (42 / 7)\")\n",
    "print(f\"ğŸ¤– [LOW] å›ç­”: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹å¯¹æ¯”\n",
    "\n",
    "HIGH çº§åˆ«ä¼šæœ‰æ›´è¯¦ç»†çš„æ€è€ƒè¿‡ç¨‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”µ LOW çº§åˆ«æ€è€ƒ:\n",
      "ğŸ¤– å›ç­”: 1000 é™¤ä»¥ 7 çº¦ç­‰äº 142.86ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”µ LOW çº§åˆ«æ€è€ƒ:\")\n",
    "agent_low = create_agent(\"LOW\")\n",
    "response = await ask(agent_low, \"1000 é™¤ä»¥ 7 ç­‰äºå¤šå°‘ï¼Ÿä¿ç•™ä¸¤ä½å°æ•°ã€‚\", show_thinking=True)\n",
    "print(f\"ğŸ¤– å›ç­”: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”´ HIGH çº§åˆ«æ€è€ƒ:\n",
      "ğŸ¤– å›ç­”: 1000 é™¤ä»¥ 7 ç­‰äº 142.86ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”´ HIGH çº§åˆ«æ€è€ƒ:\")\n",
    "agent_high = create_agent(\"HIGH\")\n",
    "response = await ask(agent_high, \"1000 é™¤ä»¥ 7 ç­‰äºå¤šå°‘ï¼Ÿä¿ç•™ä¸¤ä½å°æ•°ã€‚\", show_thinking=True)\n",
    "print(f\"ğŸ¤– å›ç­”: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. æ€»ç»“\n",
    "\n",
    "### é€‰æ‹©å»ºè®®\n",
    "\n",
    "```\n",
    "ç®€å•èŠå¤©  â†’  MINIMALï¼ˆæœ€çœé’±æœ€å¿«ï¼‰\n",
    "æ—¥å¸¸ä»»åŠ¡  â†’  LOWï¼ˆæ¨èé»˜è®¤ï¼‰\n",
    "åˆ†æä»»åŠ¡  â†’  MEDIUM\n",
    "å¤æ‚æ¨ç†  â†’  HIGHï¼ˆæœ€å‡†ä½†æœ€æ…¢ï¼‰\n",
    "```\n",
    "\n",
    "### æ€è€ƒè¿‡ç¨‹æ˜¾ç¤º\n",
    "\n",
    "```python\n",
    "# part.thought = True è¡¨ç¤ºè¿™æ˜¯æ€è€ƒå†…å®¹\n",
    "for part in event.content.parts:\n",
    "    if hasattr(part, 'thought') and part.thought:\n",
    "        print(\"æ€è€ƒ:\", part.text)\n",
    "```\n",
    "\n",
    "### ä¸ Gemini 2.5 çš„åŒºåˆ«\n",
    "\n",
    "| ç‰ˆæœ¬ | å‚æ•° | æ–¹å¼ |\n",
    "|------|------|------|\n",
    "| Gemini 3 | `thinking_level` | çº§åˆ«é€‰æ‹© |\n",
    "| Gemini 2.5 | `thinking_budget` | token é¢„ç®— |\n",
    "\n",
    "**æ³¨æ„ï¼šå‚æ•°ä¸èƒ½æ··ç”¨ï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‚è€ƒèµ„æ–™\n",
    "\n",
    "- [Gemini 3 Flash å®˜æ–¹å…¬å‘Š](https://blog.google/products/gemini/gemini-3-flash/)\n",
    "- [ADK æ¨¡å‹é…ç½®æ–‡æ¡£](https://google.github.io/adk-docs/agents/models/)\n",
    "- [TechCrunch æŠ¥é“](https://techcrunch.com/2025/12/17/google-launches-gemini-3-flash-makes-it-the-default-model-in-the-gemini-app/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
